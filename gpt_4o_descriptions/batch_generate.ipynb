{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import openai\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from collections import defaultdict\n",
    "\n",
    "API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a54c5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_list_items(text):\n",
    "    items = re.findall(r\"\\d+[\\).\\s-]+\\s*(.+?)(?=\\n\\d+[\\).\\s-]+|\\Z)\", text.strip(), re.DOTALL)\n",
    "    return [item.strip().rstrip(\".\") + \".\" for item in items if item]\n",
    "\n",
    "def get_article(word):\n",
    "    return \"an\" if word[0].lower() in \"aeiou\" else \"a\"\n",
    "\n",
    "def fill_prompt_templates(template_list, category_name):\n",
    "    filled = []\n",
    "    article = get_article(category_name)\n",
    "    \n",
    "    for template in template_list:\n",
    "        placeholder_count = template.count(\"{}\")\n",
    "        \n",
    "        if placeholder_count == 1:\n",
    "            filled.append(template.format(category_name))\n",
    "        elif placeholder_count == 2:\n",
    "            filled.append(template.format(article, category_name))\n",
    "            \n",
    "    return filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f494001",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates = { \n",
    "    \"cars\": [\n",
    "        \"How can you identify {} {}?\",\n",
    "        \"Description of {} {}, a type of car.\",\n",
    "        \"A caption of a photo of {} {}:\",\n",
    "        \"What are the primary characteristics of {} {}?\",\n",
    "        \"Description of the exterior of {} {}.\",\n",
    "        \"What are the identifying characteristics of {} {}, a type of car?\",\n",
    "        \"Describe an image from the internet of {} {}.\",\n",
    "        \"What does {} {} look like?\",\n",
    "        \"Describe what {} ‚Äú{}‚Äù, a type of car, looks like.\",\n",
    "        \"List the visual cues that help in identifying {} ‚Äú{}‚Äù.\"\n",
    "    ],\n",
    "    # \"pets\": [\n",
    "    #     \"Describe what a pet {} looks like.\",\n",
    "    #     \"Visually describe {} '{}', a type of pet.\"\n",
    "    # ],\n",
    "    # \"dtd\": [\n",
    "    #     \"What does a ‚Äú{}‚Äù material look like?\",\n",
    "    #     \"What does a ‚Äú{}‚Äù surface look like?\",\n",
    "    #     \"What does a ‚Äú{}‚Äù texture look like?\",\n",
    "    #     \"What does a ‚Äú{}‚Äù object look like?\",\n",
    "    #     \"What does a ‚Äú{}‚Äù thing look like?\",\n",
    "    #     \"What does a ‚Äú{}‚Äù pattern look like?\"\n",
    "    # ],\n",
    "    # \"resisc45\": [\n",
    "    #     \"Describe a satellite photo of {} {}.\",\n",
    "    #     \"Describe {} {} as it would appear in an aerial image.\",\n",
    "    #     \"How can you identify {} {} in an aerial photo?\",\n",
    "    #     \"Describe the satellite photo of {} {}.\",\n",
    "    #     \"Describe an aerial photo of {} {}.\"\n",
    "    # ],\n",
    "    # \"flowers\": [\n",
    "    #     \"Describe how to identify {} {}, a type of flower.\",\n",
    "    #     \"What does {} {} flower look like?\"\n",
    "    # ],\n",
    "    # \"fgvc\": [\n",
    "    #     \"What does {} {} look like?\",\n",
    "    #     \"Describe the exterior of {} {} aircraft.\",\n",
    "    #     \"Visually distinguishing features of {} {} airplane?\",\n",
    "    #     \"What are the primary characteristics of {} {}?\",\n",
    "    # ],\n",
    "    # \"ucf101\":[\n",
    "    #     \"Describe the action of {} in a photo.\",\n",
    "    #     \"What does the act of {} look like in an image?\",\n",
    "    #     \"Describe key visual features of ‚Äú{}‚Äù.\",\n",
    "    #     \"Describe the action ‚Äú{}‚Äù.\"\n",
    "    # ],\n",
    "    # \"eurosat\": [\n",
    "    #     \"Describe a satellite photo of {} ‚Äú{}‚Äù.\",\n",
    "    #     \"Describe {} ‚Äú{}‚Äù as it would appear in an aerial image.\",\n",
    "    #     \"How can you identify {} ‚Äú{}‚Äù in an aerial photo?\",\n",
    "    #     \"Describe the satellite photo of {} ‚Äú{}‚Äù.\",\n",
    "    #     \"Describe an aerial photo of {} ‚Äú{}‚Äù.\",\n",
    "    #     \"List how one can recognize the {} ‚Äú{}‚Äù within an aerial image.\",\n",
    "    #     \"List the distinguishing features of the {} ‚Äú{}‚Äù in a satellite photo.\",\n",
    "    #     \"List the visual cues that help in identifying the {} ‚Äú{}‚Äù in an aerial image.\",\n",
    "    #     \"List the visual characteristics that make the {} ‚Äú{}‚Äù easily identifiable in a satellite image.\",\n",
    "    #     \"List how one can identify the {} ‚Äú{}‚Äù based on visual cues in an aerial photo.\"\n",
    "    # ],\n",
    "    # \"gtsrb\": [\n",
    "    #     \"What does a ‚Äú{}‚Äù traffic sign look like?\",\n",
    "    #     \"Describe where the {} sign visually appears on roads.\",\n",
    "    #     \"Visually describe a road sign that indicates ‚Äú{}‚Äù.\",\n",
    "    #     \"What are unique visual features of a ‚Äú{}‚Äù traffic sign commonly found in Germany?\",\n",
    "    # ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc823e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metadata = {\n",
    "    \"cars\": \"car model\",\n",
    "    \"pets\": \"pet type\",\n",
    "    \"dtd\": \"texture type\",\n",
    "    \"resisc45\": \"aerial location\",\n",
    "    \"flowers\": \"flower species\",\n",
    "    \"fgvc\": \"aircraft model\",\n",
    "    \"ucf101\": \"action\",\n",
    "    \"eurosat\": \"prompted location\",\n",
    "    \"gtsrb\": \"traffic sign type\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b28a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS_PER_FILE = 90000\n",
    "ENCODING = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e7fa8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cars: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:00<00:00, 2045.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote batch_jobs/cars_batch_prompts_part0.jsonl with 1477 tasks and ~89951 tokens.\n",
      "Wrote batch_jobs/cars_batch_prompts_part1.jsonl with 483 tasks and ~29761 tokens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Token counter functions\n",
    "def count_tokens(text):\n",
    "    return len(ENCODING.encode(text))\n",
    "\n",
    "def count_chat_tokens(messages):\n",
    "    tokens_per_message = 3\n",
    "    tokens_per_name = 1\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += count_tokens(value)\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    return num_tokens + 3  # priming\n",
    "\n",
    "# Main batching logic\n",
    "for dataset in prompt_templates.keys():\n",
    "    with open(\"../configs/classes.json\", 'r') as f:\n",
    "        classes = json.load(f)[dataset]\n",
    "\n",
    "    current_file_idx = 0\n",
    "    current_token_count = 0\n",
    "    current_tasks = []\n",
    "\n",
    "    for category in tqdm(classes, desc=f\"Processing {dataset}\"):\n",
    "        prompts = fill_prompt_templates(prompt_templates[dataset], category)\n",
    "\n",
    "        for index, curr_prompt in enumerate(prompts):\n",
    "            system_msg = \"You are a helpful assistant. Give 10 numbered sentences answering prompt as visually identifiable descriptions.\"\n",
    "            user_msg = curr_prompt + f\" Include '{category}' in each sentence.\"\n",
    "\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_msg},\n",
    "                {\"role\": \"user\", \"content\": user_msg},\n",
    "            ]\n",
    "            estimated_tokens = count_chat_tokens(messages)\n",
    "\n",
    "            if current_token_count + estimated_tokens > MAX_TOKENS_PER_FILE:\n",
    "                file_name = f\"batch_jobs/{dataset}_batch_prompts_part{current_file_idx}.jsonl\"\n",
    "                os.makedirs(\"batch_jobs\", exist_ok=True)\n",
    "                with open(file_name, 'w') as file:\n",
    "                    for obj in current_tasks:\n",
    "                        file.write(json.dumps(obj) + '\\n')\n",
    "                print(f\"Wrote {file_name} with {len(current_tasks)} tasks and ~{current_token_count} tokens.\")\n",
    "\n",
    "                current_file_idx += 1\n",
    "                current_tasks = []\n",
    "                current_token_count = 0\n",
    "\n",
    "            task = {\n",
    "                \"custom_id\": f\"{dataset}#{category}#{index}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"messages\": messages,\n",
    "                }\n",
    "            }\n",
    "\n",
    "            current_tasks.append(task)\n",
    "            current_token_count += estimated_tokens\n",
    "\n",
    "    if current_tasks:\n",
    "        file_name = f\"batch_jobs/{dataset}_batch_prompts_part{current_file_idx}.jsonl\"\n",
    "        with open(file_name, 'w') as file:\n",
    "            for obj in current_tasks:\n",
    "                file.write(json.dumps(obj) + '\\n')\n",
    "        print(f\"Wrote {file_name} with {len(current_tasks)} tasks and ~{current_token_count} tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1220fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì§ Submitting batch part 0: batch_jobs/cars_batch_prompts_part0.jsonl\n",
      "üöÄ Submitted batch (part 0) with ID: batch_682abd7cf8408190be7178c87af44227\n",
      "üîÑ Waiting... Batch batch_682abd7cf8408190be7178c87af44227 is currently: validating\n",
      "üîÑ Waiting... Batch batch_682abd7cf8408190be7178c87af44227 is currently: failed\n",
      "‚ùå Batch batch_682abd7cf8408190be7178c87af44227 failed. Exiting.\n"
     ]
    }
   ],
   "source": [
    "dataset = \"cars\"\n",
    "batch_folder = \"batch_jobs\"\n",
    "pattern = os.path.join(batch_folder, f\"{dataset}_batch_prompts*.jsonl\")\n",
    "file_paths = sorted(glob.glob(pattern))  # Match part files if exist, or the single file\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Check if files exist\n",
    "if not file_paths:\n",
    "    raise FileNotFoundError(f\"No batch prompt files found for dataset: {dataset}\")\n",
    "\n",
    "# Wait function to poll batch status\n",
    "def wait_for_batch_completion(client, batch_id, poll_interval=30):\n",
    "    while True:\n",
    "        batch_status = client.batches.retrieve(batch_id).status\n",
    "        print(f\"üîÑ Waiting... Batch {batch_id} is currently: {batch_status}\")\n",
    "\n",
    "        if batch_status == \"completed\":\n",
    "            print(f\"‚úÖ Batch {batch_id} completed.\")\n",
    "            return True\n",
    "        elif batch_status == \"failed\":\n",
    "            print(f\"‚ùå Batch {batch_id} failed. Exiting.\")\n",
    "            return False\n",
    "        time.sleep(poll_interval)\n",
    "\n",
    "# Submit batches sequentially\n",
    "for idx, file_path in enumerate(file_paths):\n",
    "    if idx > 0:\n",
    "        # Wait for the previous batch to complete before continuing\n",
    "        success = wait_for_batch_completion(client, prev_batch_id)\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "    print(f\"\\nüì§ Submitting batch part {idx}: {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        batch_input_file = client.files.create(file=file, purpose=\"batch\")\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "    batch = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Sathira - Batch job for generating prompts for {dataset}, part {idx}.\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    prev_batch_id = batch.id\n",
    "    print(f\"üöÄ Submitted batch (part {idx}) with ID: {batch.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "792e9eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_682aba65ad608190a35be87805ca2ab0', completion_window='24h', created_at=1747630693, endpoint='/v1/chat/completions', input_file_id='file-7aAmKAKNhA3LAfJdZkWNXb', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747630821, error_file_id=None, errors=None, expired_at=None, expires_at=1747717093, failed_at=None, finalizing_at=1747630786, in_progress_at=1747630696, metadata={'description': 'Sathira - Batch job for generating prompts for cars, part 1.'}, output_file_id='file-7zRJXFB4S2GAh6wVqqdSWH', request_counts=BatchRequestCounts(completed=596, failed=0, total=596))\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=API_KEY)\n",
    "batch = client.batches.retrieve(\"batch_682aba65ad608190a35be87805ca2ab0\")\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09364b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_batch_response(file_ids, client: OpenAI, output_dir=\".\"):\n",
    "    dataset_wise = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for file_id in file_ids:\n",
    "        print(f\"üì• Fetching file content from: {file_id}\")\n",
    "        try:\n",
    "            # Download batch output text\n",
    "            batch_text = client.files.content(file_id).text\n",
    "\n",
    "            for line in batch_text.strip().split(\"\\n\"):\n",
    "                data = json.loads(line)\n",
    "\n",
    "                # Skip lines without a valid response\n",
    "                if \"response\" not in data:\n",
    "                    continue\n",
    "\n",
    "                custom_id = data.get(\"custom_id\", \"\")\n",
    "                parts = custom_id.split(\"#\")\n",
    "                if len(parts) < 2:\n",
    "                    continue  # malformed custom_id\n",
    "\n",
    "                dataset, class_name = parts[0], parts[1]\n",
    "\n",
    "                try:\n",
    "                    content = data[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "                    items = extract_list_items(content)\n",
    "                    dataset_wise[dataset][class_name].extend(items)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to process {custom_id}: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error downloading or parsing file {file_id}: {e}\")\n",
    "\n",
    "    # Save one JSON file per dataset\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for dataset, class_dict in dataset_wise.items():\n",
    "        output_path = os.path.join(output_dir, f\"{dataset}.json\")\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(class_dict, f, indent=4)\n",
    "        print(f\"‚úÖ Saved: {output_path}\")\n",
    "\n",
    "    print(f\"üéâ Done! Parsed datasets: {', '.join(dataset_wise.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a3b49b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Fetching file content from: file-MPn3syhgDFnrCUXvpVsCZA\n",
      "üì• Fetching file content from: file-7zRJXFB4S2GAh6wVqqdSWH\n",
      "‚úÖ Saved: ./cars.json\n",
      "üéâ Done! Parsed datasets: cars\n"
     ]
    }
   ],
   "source": [
    "descriptions = parse_batch_response(['file-MPn3syhgDFnrCUXvpVsCZA', 'file-7zRJXFB4S2GAh6wVqqdSWH'], client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3671a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{dataset}v2.json\", 'w') as f:\n",
    "    json.dump(descriptions, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee8ef92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
